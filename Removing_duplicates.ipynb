{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMtBgMJZEff7zjqcGQBHY9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pithi1910/ENCORED-DATA_ANALYSE/blob/main/Removing_duplicates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMq1HNHoU4Rz",
        "outputId": "25d5b70a-6dc2-4efe-adb8-a829a6a869d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows before removing duplicates: 32561\n",
            "Number of rows after removing duplicates: 32537\n",
            "Number of duplicate rows removed: 24\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming the dataset file is in the same directory as your script, or you provide the correct path\n",
        "file_path = \"adult.data\"\n",
        "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
        "                'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
        "                'hours_per_week', 'native_country', 'income']\n",
        "\n",
        "# Load the dataset\n",
        "adult_data = pd.read_csv(file_path, names=column_names, na_values=' ?')  # Handling missing values represented as ' ?'\n",
        "\n",
        "# Check the number of rows before removing duplicates\n",
        "print(\"Number of rows before removing duplicates:\", len(adult_data))\n",
        "\n",
        "# Identify and remove duplicate rows by filtering based on the 'duplicated' column\n",
        "adult_data_no_duplicates = adult_data[~adult_data.duplicated()]\n",
        "\n",
        "# Check the number of rows after removing duplicates\n",
        "print(\"Number of rows after removing duplicates:\", len(adult_data_no_duplicates))\n",
        "\n",
        "# Optional: Verify that duplicates have been removed\n",
        "duplicate_count = len(adult_data) - len(adult_data_no_duplicates)\n",
        "print(\"Number of duplicate rows removed:\", duplicate_count)"
      ]
    }
  ]
}